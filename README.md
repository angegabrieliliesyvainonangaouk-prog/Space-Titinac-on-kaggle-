# Space-Titinac-machine-learning-project

This project is based on the Spaceship Titanic competition
on Kaggle. The goal is to predict whether a passenger of the Spaceship Titanic was transported to another dimension after an incident.


Ce projet est bas√© sur la comp√©tition Spaceship Titanic
sur Kaggle. Le but est de pr√©dire si un passager du vaisseau spatial Titanic a √©t√© transport√© vers une autre dimension apr√®s un incident.

This project demonstrates my skills in data cleaning, feature engineering, modeling, and evaluation of Machine Learning models, while following a professional workflow to solve real-world problems.

Ce projet permet de d√©montrer mes comp√©tences en nettoyage de donn√©es, cr√©ation de nouvelles features, mod√©lisation et √©valuation de mod√®les de Machine Learning, tout en appliquant une m√©thodologie professionnelle et surtout faire comprendre aux recruteurs qui passeront sur mon compte de quoi je suis capable.

It also shows that I can perform well using a single model without any data leakage.

Il montre √©galement que je peux obtenir d‚Äôexcellents r√©sultats avec un seul mod√®le, sans aucune fuite de donn√©es.

Objectives / Objectifs

Explore and understand the dataset (EDA)

Clean and prepare data for modeling (handle missing values intelligently or with an ‚Äúunknown‚Äù category, encode categorical variables properly)

Build, compare, and optimize Machine Learning models (RandomForest, Gradient Boosting, LightGBM, XGBoost)

Present clear and reproducible results

Demonstrate the impact of feature selection and algorithm choice on model performance (using Mutual Information, Seaborn visualization, and permutation importance)

 (VF)
Explorer et comprendre les donn√©es (EDA)

Nettoyer et pr√©parer les donn√©es pour la mod√©lisation (gestion intelligente des valeurs manquantes ou cr√©ation d‚Äôune cat√©gorie ‚Äúunknown‚Äù, encodage adapt√© des variables cat√©gorielles)

L'utilisation d'un seul mod√®le pour performer efficacement

Pr√©senter des r√©sultats clairs et reproductibles

Montrer l‚Äôimpact du choix des features et des algorithmes sur la performance du mod√®le (Mutual Information, visualisation Seaborn, permutation importance)

Technologies and Libraries / Technologies et Librairies

Python 3

Pandas / NumPy ‚Äì data manipulation / manipulation de donn√©es

Scikit-learn ‚Äì modeling and pipelines / mod√©lisation et pipelines

Matplotlib / Seaborn ‚Äì visualization 

SHAP ‚Äì explainability / interpr√©tabilit√©

LightGBM   machine learning models


 Methodology / M√©thodologie
1. Exploratory Data Analysis (EDA) / Analyse exploratoire

Count dataset rows and columns / Comptage des lignes et colonnes

Find the topic of each data / Comprendre le th√®me et la logique derri√®re les jeux de donn√©e

Detect rare categories that may bias MI / D√©tection des cat√©gories rares qui peuvent biaiser le MI

Identify string columns to create new features / Identification des colonnes √† d√©couper en nouvelles features


2. Data Preprocessing / Pr√©traitement des donn√©es

Handle missing values intelligently / Gestion intelligente des valeurs manquantes

Encode categorical variables according to their type (nominal/ordinal)(to add in  this model) / Encodage des variables cat√©gorielles selon leur nature (nominale ou ordinale)(√†  ajouter dans ce mod√®le)

3. Feature Selection / S√©lection de Features

Use Mutual Information (MI) to test dependency between features and target / Utilisation du MI de mani√®re innovantes  pour tester la d√©pendance entre les features  et la cible

Use MI to test dependency between features themselves / Utilisation du MI pour d√©tecter les redondances entre colonnes

Remove redundant features / Suppression des colonnes fortement dependantes 

Create new engineered features based on logic and MI results / Cr√©ation de nouvelles features √† partir de ma logique et des r√©sultats du MI 

Evaluate importance via permutation and model-based ranking / √âvaluation de l‚Äôimportance via permutation et mod√®les de base

4. Modeling / Mod√©lisation

I used LightGBM as my main model to focus on advanced feature engineering and faster iterations.
J‚Äôai utilis√© LightGBM comme mod√®le principal afin de concentrer mon travail sur le feature engineering et de r√©duire le temps d‚Äôexp√©rimentation.

I applied Optuna for hyperparameter tuning, and used Stratified K-Fold cross-validation to ensure balanced class splits and better generalization.

J‚Äôai utilis√© Optuna pour l‚Äôoptimisation des hyperparam√®tres et Stratified K-Fold pour assurer une meilleure g√©n√©ralisation du mod√®le.

5. Evaluation / √âvaluation

Metric: Accuracy

Cross-validation: Stratified K-Fold

 (VF)
Metric : Accuracy

Validation crois√©e : Stratified K-Fold



Results / R√©sultats

used model: LightGBM

Best Kaggle score: 0.80734 accuracy

Most important features:  "CryoSleep","deckhome" ,TotalSpend etc..

Mod√®le utilis√© : LightGBM

Meilleur score Kaggle : 0,80734 accuracy

Features les plus importantes : "CryoSleep","deckhome" ,TotalSpend etc..

 CodeSpace

You can explore my notebook to see how I explain each choice and step of my workflow.
Vous pouvez consulter mon notebook pour voir comment j‚Äôexplique chacun de mes choix et ma mani√®re de travailler.Il se trouve dans le fichier space_titanic_CodeSpace

üß© Conclusion / Conclusion

This project highlights my ability to:

Structure an end-to-end Machine Learning workflow

Handle missing values and categorical variables effectively

Build and evaluate performant ML models

Communicate results clearly and professionally

Ce projet met en avant ma capacit√© √† :

Structurer un projet Machine Learning de bout en bout

G√©rer les donn√©es manquantes et cat√©gorielles avec logique et rigueur

Construire et √©valuer des mod√®les performants

Communiquer mes r√©sultats de mani√®re claire et professionnelle

I‚Äôm aware that I still have a lot to learn, but I improve every day and constantly do research to push my limits. If this project doesn‚Äôt yet meet your expectations for a paid internship, I invite you to look at my House Price Advanced project (ranked 61/5394 without data leakage), where I implemented specific encodings for each type of feature, target encoding for high-cardinality variables, redundancy management, and skewness correction.If after that ,you want see more ,like I love challenges and competition feel free to test me.

(VF)
Je suis conscient qu‚Äôil me reste encore  des choses √† apprendre , c'est pour cette raison que je suis ouvert √† toutes les propositions professionnelles (Stage remun√©r√© ,internship, job junior en ML, data scientit, research IA... ).Tant que vous permettez de continuer mes recherches   de mani√®re approfondi et aussi me nourrir  je suis √† l'√©coute.  Si ce projet n‚Äôatteint pas encore vos attentes ,  je vous invite √† regarder mon projet House Price Advanced (61·µâ/5394 sans fuite de donn√©es), o√π j‚Äôai mis en place des encodages sp√©cifiques, un target encoding pour les variables √† forte cardinalit√©, une gestion des redondances et une correction des skewness.
Et si apr√®s √ßa vous n'√™tes pas convaincu de mon talent ,comme J‚Äôaime les d√©fis et la comp√©tition n‚Äôh√©sitez pas √† me challenger.


